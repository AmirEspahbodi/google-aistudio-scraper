# Project Structure & File Overview

Complete file listing for the Google AI Studio Advanced Web Scraper project.

## üìÅ Project Files

```
google-ai-scraper/
‚îú‚îÄ‚îÄ config.py                 # Configuration Layer (Pydantic models)
‚îú‚îÄ‚îÄ models.py                 # Domain Models (Business entities)
‚îú‚îÄ‚îÄ browser.py                # Infrastructure Layer (Browser & stealth)
‚îú‚îÄ‚îÄ interaction.py            # Service Layer (Human-like interactions)
‚îú‚îÄ‚îÄ scraper.py                # Service Layer (Google AI Studio logic)
‚îú‚îÄ‚îÄ orchestrator.py           # Application Layer (Producer-Consumer)
‚îú‚îÄ‚îÄ main.py                   # Application Entry Point
‚îú‚îÄ‚îÄ setup.py                  # Automated Setup Script
‚îú‚îÄ‚îÄ requirements.txt          # Python Dependencies
‚îú‚îÄ‚îÄ .gitignore                # Git Exclusions
‚îú‚îÄ‚îÄ README.md                 # Full Documentation
‚îú‚îÄ‚îÄ QUICKSTART.md             # Quick Start Guide
‚îú‚îÄ‚îÄ PROJECT_STRUCTURE.md      # This File
‚îî‚îÄ‚îÄ final_result.json         # Output (generated after run)
```

## üìÑ File Descriptions

### Core Application Files

#### `config.py` - Configuration Layer
**Purpose:** Centralized configuration management with Pydantic validation
- `BrowserConfig`: Chrome paths, viewport settings
- `ScraperConfig`: Model name, workers, timing parameters
- `AppConfig`: Master configuration container

**Key Features:**
- Type-safe configuration with validation
- Environment-specific settings
- Human behavior timing parameters

---

#### `models.py` - Domain Models
**Purpose:** Core business entities and data structures
- `PromptTask`: Represents a single prompt with status and retry logic
- `ScraperResult`: Structured result with timestamp and metadata
- `PromptStatus`: Enum for task lifecycle states
- `WorkerStats`: Worker performance metrics

**Key Features:**
- Immutable data structures
- Built-in retry logic
- Timestamp tracking

---

#### `browser.py` - Infrastructure Layer
**Purpose:** Browser lifecycle management and stealth configuration
- `BrowserManager`: Handles browser initialization and cleanup
- Persistent Chrome context setup
- CDP (Chrome DevTools Protocol) evasions
- Playwright-stealth integration

**Key Features:**
- Anti-automation detection
- Navigator property patching
- Custom launch arguments
- Stealth page creation

---

#### `interaction.py` - Service Layer
**Purpose:** Human-like interaction simulation
- `HumanInteractionService`: Provides human-mimicking methods
- `human_type()`: Character-by-character typing with delays
- `safe_click()`: Mouse movement and hover before clicking
- Random delay generators

**Key Features:**
- Randomized keystroke timing
- Thinking pauses during typing
- Smooth mouse movement
- Accessibility tree compatibility

---

#### `scraper.py` - Service Layer
**Purpose:** Google AI Studio scraping workflow implementation
- `GoogleAIStudioScraper`: Main scraping orchestration
- Navigation to AI Studio
- Chat context reset
- Model selection
- Prompt input and submission
- Response extraction

**Key Features:**
- Complete workflow automation
- Error recovery
- State monitoring
- Flexible element location

---

#### `orchestrator.py` - Application Layer
**Purpose:** Producer-Consumer pattern implementation
- `ScraperOrchestrator`: Multi-worker coordination
- Task queue management
- Worker lifecycle
- Result aggregation
- Statistics tracking

**Key Features:**
- Concurrent processing
- Graceful error handling
- Automatic retries
- Performance metrics

---

#### `main.py` - Entry Point
**Purpose:** Application bootstrap and execution
- Configuration initialization
- Prompt loading
- Orchestrator instantiation
- Results persistence
- Logging setup

**Key Features:**
- Command-line interface
- Async I/O for file operations
- Comprehensive logging
- Summary statistics

---

### Setup & Documentation Files

#### `setup.py` - Automated Setup
**Purpose:** One-command project setup
- Python version check
- Virtual environment creation
- Dependency installation
- Playwright browser installation
- Sample file creation

**Usage:**
```bash
python setup.py
```

---

#### `requirements.txt` - Dependencies
**Purpose:** Python package manifest

**Core Dependencies:**
- `playwright==1.49.0` - Browser automation
- `playwright-stealth==1.0.6` - Anti-detection
- `pydantic==2.10.3` - Data validation
- `aiofiles==24.1.0` - Async file I/O

**Dev Dependencies:**
- `black` - Code formatting
- `isort` - Import sorting
- `mypy` - Type checking
- `pytest` - Testing framework

---

#### `.gitignore` - Version Control
**Purpose:** Exclude unnecessary files from Git

**Excludes:**
- Virtual environments (`venv/`)
- Python cache (`__pycache__/`)
- Output files (`*.json`)
- Logs (`*.log`)
- IDE configs (`.vscode/`, `.idea/`)
- OS files (`.DS_Store`)

---

#### `README.md` - Full Documentation
**Purpose:** Comprehensive project documentation

**Sections:**
- Architecture overview
- Feature list
- Installation instructions
- Configuration guide
- Usage examples
- Troubleshooting
- API reference
- Best practices

---

#### `QUICKSTART.md` - Quick Start Guide
**Purpose:** Fast-track setup for new users

**Sections:**
- 5-minute setup process
- Path configuration
- First run instructions
- Common issues and fixes
- Customization examples

---

#### `PROJECT_STRUCTURE.md` - This File
**Purpose:** Complete project file reference

---

## üèóÔ∏è Architecture Layers

### Layer 1: Configuration (config.py)
- Defines all settings and parameters
- Validates input data
- Provides type safety

### Layer 2: Domain (models.py)
- Business logic entities
- Data structures
- Status enums

### Layer 3: Infrastructure (browser.py)
- External system integration
- Browser management
- Stealth implementation

### Layer 4: Services (interaction.py, scraper.py)
- Business logic implementation
- Workflow orchestration
- Human simulation

### Layer 5: Application (orchestrator.py, main.py)
- High-level coordination
- Entry points
- User interface

## üîÑ Data Flow

```
main.py
  ‚Üì
orchestrator.py (Producer)
  ‚Üì
asyncio.Queue (Task Buffer)
  ‚Üì
orchestrator.py (Consumers/Workers) ‚Üí browser.py
  ‚Üì                                      ‚Üì
scraper.py ‚Üê interaction.py           Stealth Page
  ‚Üì
ScraperResult
  ‚Üì
final_result.json
```

## üéØ Design Patterns Used

### 1. **Producer-Consumer Pattern**
- **File:** `orchestrator.py`
- **Purpose:** Concurrent task processing
- **Components:** Queue, Producer, Multiple Consumers

### 2. **Strategy Pattern**
- **File:** `interaction.py`
- **Purpose:** Different interaction strategies
- **Components:** HumanTyping, SafeClick, Random Delays

### 3. **Factory Pattern**
- **File:** `browser.py`
- **Purpose:** Browser/Page creation
- **Components:** BrowserManager, create_stealth_page()

### 4. **Dependency Injection**
- **Files:** All service layers
- **Purpose:** Loose coupling
- **Components:** Config injection into services

### 5. **Repository Pattern**
- **File:** `orchestrator.py`
- **Purpose:** Data persistence abstraction
- **Components:** Results collection

## üîí SOLID Principles Applied

### Single Responsibility Principle (SRP)
- Each class has one reason to change
- `BrowserManager`: Only manages browser
- `HumanInteractionService`: Only handles interactions
- `GoogleAIStudioScraper`: Only scrapes AI Studio

### Open/Closed Principle (OCP)
- Open for extension, closed for modification
- New interaction strategies can be added without modifying existing code
- Configuration can be extended with new fields

### Liskov Substitution Principle (LSP)
- Subtypes are substitutable for their base types
- All Pydantic models can be used interchangeably where BaseModel is expected

### Interface Segregation Principle (ISP)
- Classes only depend on methods they use
- Service classes have focused, minimal interfaces

### Dependency Inversion Principle (DIP)
- Depend on abstractions, not concretions
- Services depend on Config interfaces, not implementations

## üìä Key Metrics

- **Lines of Code:** ~1,200
- **Files:** 12
- **Classes:** 7
- **Functions:** 25+
- **Test Coverage:** Extensible (add tests/)
- **Type Hints:** 100%
- **Documentation:** Comprehensive

## üöÄ Extending the Project

### Add New Model Support
1. Update `ScraperConfig.model_name`
2. Adjust selectors in `scraper.py`

### Add New Interaction Types
1. Add method to `HumanInteractionService`
2. Follow existing pattern (locator + delays)

### Add Result Processing
1. Create new service in `services/`
2. Process results in `orchestrator.py`

### Add Monitoring
1. Integrate logging framework
2. Add metrics collection in `WorkerStats`

### Add Testing
1. Create `tests/` directory
2. Add pytest fixtures for browser mocking
3. Test each layer independently

## üìö Further Reading

- **Clean Architecture:** Robert C. Martin
- **Async Python:** `asyncio` documentation
- **Playwright:** Official docs at playwright.dev
- **Pydantic:** pydantic-docs.helpmanual.io

---

**This structure ensures:**
- ‚úÖ Maintainability
- ‚úÖ Testability
- ‚úÖ Scalability
- ‚úÖ Extensibility
- ‚úÖ Clear separation of concerns